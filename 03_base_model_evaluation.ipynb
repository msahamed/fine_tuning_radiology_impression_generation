{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f533706-9af8-4456-a15d-3b747aeed48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import load_from_disk\n",
    "from transformers import pipeline, StoppingCriteria\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from transformers import pipeline, StoppingCriteria\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import evaluate\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a593ec6-62a6-4492-be67-f1047bff15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Create comparative generation function\n",
    "def generate_comparative_answers(findings):\n",
    "    \"\"\"Generate answers from both base and fine-tuned models\"\"\"\n",
    "\n",
    "    system_message = \"\"\"You are an expert radiologist assistant specializing in generating accurate and concise medical impressions from radiology\n",
    "       findings.\n",
    "    \n",
    "      Your task is to:\n",
    "      1. **Analyze the findings**: Carefully review all clinical findings, history, and technique information\n",
    "      2. **Generate focused impressions**: Create clear, prioritized conclusions that directly address the clinical question\n",
    "      3. **Maintain clinical accuracy**: Ensure all significant findings are appropriately characterized\n",
    "      4. **Use appropriate medical terminology**: Follow standard radiological reporting conventions\n",
    "      5. **Adapt communication style**: Match the institutional reporting style and level of detail expected\n",
    "    \n",
    "      Generate only the IMPRESSION section based on the provided clinical information.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": findings},\n",
    "    ]\n",
    "\n",
    "    # Base model pipeline\n",
    "    base_pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=base_model,\n",
    "        tokenizer=base_tokenizer,\n",
    "    )\n",
    "\n",
    "    # Fine-tuned model pipeline (reuse existing)\n",
    "    ft_pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=ft_model,\n",
    "        tokenizer=ft_tokenizer,\n",
    "    )\n",
    "\n",
    "    # Generation arguments\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": 300,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 0.0,\n",
    "        \"do_sample\": False,\n",
    "        \"stopping_criteria\": [EosListStoppingCriteria()]\n",
    "    }\n",
    "\n",
    "    # Generate from both models\n",
    "    base_output = base_pipe(messages, **generation_args)\n",
    "    ft_output = ft_pipe(messages, **generation_args)\n",
    "\n",
    "    return {\n",
    "        'base': base_output[0]['generated_text'].strip(),\n",
    "        'finetuned': ft_output[0]['generated_text'].strip()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bce2bd0-48e8-476b-8a03-5ea20f6a96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModalityBasedEvaluator:\n",
    "    def __init__(self,\n",
    "                 dataset_path=\"./data/processed/radiology_datasets\"\n",
    "            ):\n",
    "        \"\"\"Initialize the systematic evaluator\"\"\"\n",
    "        \n",
    "        self.load_model()\n",
    "        self.load_dataset(dataset_path)\n",
    "        self.results = defaultdict(list)\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load fine-tuned model\"\"\"\n",
    "        print(\"Loading fine-tuned model...\")\n",
    "        base_model_name = \"microsoft/MediPhi-Instruct\"\n",
    "        self.ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        self.ft_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            base_model_name,\n",
    "            trust_remote_code=True,\n",
    "            padding_side=\"right\"\n",
    "        )\n",
    "\n",
    "    def load_dataset(self, dataset_path):\n",
    "        \"\"\"Load evaluation dataset\"\"\"\n",
    "        print(\"Loading dataset...\")\n",
    "        self.dataset = load_from_disk(dataset_path)\n",
    "        self.test_data = self.dataset['test']\n",
    "\n",
    "        # Convert to pandas for easier analysis\n",
    "        self.test_df = pd.DataFrame(self.test_data)\n",
    "\n",
    "        print(f\"Test dataset: {len(self.test_df)} samples\")\n",
    "        print(f\"Modalities: {self.test_df['modality'].unique()}\")\n",
    "        print(f\"Clinics: {self.test_df['clinic_id'].unique()}\")\n",
    "\n",
    "    def get_modality_distribution(self):\n",
    "        \"\"\"Analyze modality distribution in test set\"\"\"\n",
    "        modality_stats = self.test_df.groupby('modality').agg({\n",
    "            'findings': 'count',\n",
    "            'clinic_id': 'nunique'\n",
    "        }).rename(columns={'findings': 'sample_count', 'clinic_id': 'clinic_count'})\n",
    "\n",
    "        return modality_stats\n",
    "\n",
    "    def generate_impression(self, findings):\n",
    "        \"\"\"Generate impression for given findings\"\"\"\n",
    "        system_message = \"\"\"You are an expert radiologist assistant specializing in generating accurate and concise medical impressions from radiology findings.\n",
    "\n",
    "        Your task is to:\n",
    "        1. **Analyze the findings**: Carefully review all clinical findings\n",
    "        2. **Generate focused impressions**: Create clear, prioritized conclusions\n",
    "        3. **Maintain clinical accuracy**: Ensure all significant findings are characterized\n",
    "        4. **Use appropriate medical terminology**: Follow standard radiological conventions\n",
    "\n",
    "        Generate only the IMPRESSION section based on the provided clinical information.\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": findings},\n",
    "        ]\n",
    "\n",
    "        pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.ft_model,\n",
    "            tokenizer=self.ft_tokenizer,\n",
    "        )\n",
    "\n",
    "        class EosListStoppingCriteria(StoppingCriteria):\n",
    "            def __init__(self, eos_sequence=[32007]):\n",
    "                self.eos_sequence = eos_sequence\n",
    "\n",
    "            def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "                last_ids = input_ids[:, -len(self.eos_sequence):].tolist()\n",
    "                return self.eos_sequence in last_ids\n",
    "\n",
    "        generation_args = {\n",
    "            \"max_new_tokens\": 300,\n",
    "            \"return_full_text\": False,\n",
    "            \"temperature\": 0.0,\n",
    "            \"do_sample\": False,\n",
    "            \"stopping_criteria\": [EosListStoppingCriteria()]\n",
    "        }\n",
    "\n",
    "        output = pipe(messages, **generation_args)\n",
    "        return output[0]['generated_text'].strip()\n",
    "\n",
    "    def evaluate_sample(self, idx):\n",
    "        \"\"\"Evaluate single sample\"\"\"\n",
    "        # Convert numpy int64 to Python int\n",
    "        idx = int(idx)\n",
    "        sample = self.test_data[idx]\n",
    "\n",
    "        findings = sample['findings']\n",
    "        reference = sample['impression']\n",
    "        modality = sample['modality']\n",
    "        clinic_id = sample['clinic_id']\n",
    "\n",
    "        # Generate prediction\n",
    "        prediction = self.generate_impression(findings)\n",
    "\n",
    "        # Compute ROUGE scores\n",
    "        rouge = evaluate.load(\"rouge\")\n",
    "        rouge_scores = rouge.compute(\n",
    "            predictions=[prediction],\n",
    "            references=[reference],\n",
    "            rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'sample_idx': idx,\n",
    "            'modality': modality,\n",
    "            'clinic_id': clinic_id,\n",
    "            'findings': findings,\n",
    "            'reference': reference,\n",
    "            'prediction': prediction,\n",
    "            'rouge1': rouge_scores['rouge1'],\n",
    "            'rouge2': rouge_scores['rouge2'],\n",
    "            'rougeL': rouge_scores['rougeL'],\n",
    "            'findings_length': len(findings),\n",
    "            'reference_length': len(reference),\n",
    "            'prediction_length': len(prediction)\n",
    "        }\n",
    "\n",
    "    def evaluate_by_modality(self, samples_per_modality=10, random_seed=42):\n",
    "        \"\"\"Systematic evaluation across all modalities\"\"\"\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        modality_results = {}\n",
    "\n",
    "        for modality in self.test_df['modality'].unique():\n",
    "            print(f\"\\n🔬 Evaluating modality: {modality}\")\n",
    "\n",
    "            # Get samples for this modality\n",
    "            modality_samples = self.test_df[self.test_df['modality'] == modality]\n",
    "\n",
    "            # Sample random subset\n",
    "            n_samples = min(samples_per_modality, len(modality_samples))\n",
    "            # Get the actual dataset indices (not DataFrame indices)\n",
    "            available_indices = list(range(len(self.test_df)))\n",
    "            modality_indices = [i for i in available_indices if self.test_df.iloc[i]['modality'] == modality]\n",
    "\n",
    "            sampled_indices = np.random.choice(\n",
    "                modality_indices,\n",
    "                size=n_samples,\n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            modality_results[modality] = []\n",
    "\n",
    "            for i, idx in enumerate(sampled_indices):\n",
    "                print(f\"  Processing sample {i+1}/{n_samples}...\")\n",
    "                result = self.evaluate_sample(idx)\n",
    "                modality_results[modality].append(result)\n",
    "\n",
    "        return modality_results\n",
    "\n",
    "    def evaluate_by_clinic_modality(self, samples_per_combination=5):\n",
    "        \"\"\"Evaluate by clinic-modality combinations\"\"\"\n",
    "        np.random.seed(42)\n",
    "\n",
    "        combination_results = {}\n",
    "\n",
    "        for combo in self.test_df['clinic_modality'].unique():\n",
    "            print(f\"\\n🏥 Evaluating combination: {combo}\")\n",
    "\n",
    "            combo_samples = self.test_df[self.test_df['clinic_modality'] == combo]\n",
    "\n",
    "            n_samples = min(samples_per_combination, len(combo_samples))\n",
    "            if n_samples == 0:\n",
    "                continue\n",
    "\n",
    "            # Get actual dataset indices for this combination\n",
    "            combo_indices = [i for i in range(len(self.test_df)) if self.test_df.iloc[i]['clinic_modality'] == combo]\n",
    "\n",
    "            sampled_indices = np.random.choice(\n",
    "                combo_indices,\n",
    "                size=n_samples,\n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            combination_results[combo] = []\n",
    "\n",
    "            for i, idx in enumerate(sampled_indices):\n",
    "                print(f\"  Processing sample {i+1}/{n_samples}...\")\n",
    "                result = self.evaluate_sample(idx)\n",
    "                combination_results[combo].append(result)\n",
    "\n",
    "        return combination_results\n",
    "\n",
    "    def compute_aggregate_metrics(self, results):\n",
    "        \"\"\"Compute aggregate metrics from evaluation results\"\"\"\n",
    "        aggregated = {}\n",
    "\n",
    "        for category, samples in results.items():\n",
    "            if not samples:\n",
    "                continue\n",
    "\n",
    "            metrics = {\n",
    "                'sample_count': len(samples),\n",
    "                'rouge1_mean': np.mean([s['rouge1'] for s in samples]),\n",
    "                'rouge1_std': np.std([s['rouge1'] for s in samples]),\n",
    "                'rouge2_mean': np.mean([s['rouge2'] for s in samples]),\n",
    "                'rouge2_std': np.std([s['rouge2'] for s in samples]),\n",
    "                'rougeL_mean': np.mean([s['rougeL'] for s in samples]),\n",
    "                'rougeL_std': np.std([s['rougeL'] for s in samples]),\n",
    "                'avg_findings_length': np.mean([s['findings_length'] for s in samples]),\n",
    "                'avg_reference_length': np.mean([s['reference_length'] for s in samples]),\n",
    "                'avg_prediction_length': np.mean([s['prediction_length'] for s in samples])\n",
    "            }\n",
    "\n",
    "            aggregated[category] = metrics\n",
    "\n",
    "        return aggregated\n",
    "\n",
    "    def generate_evaluation_report(self, modality_results, combination_results=None):\n",
    "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📊 SYSTEMATIC EVALUATION REPORT\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Modality-based metrics\n",
    "        modality_metrics = self.compute_aggregate_metrics(modality_results)\n",
    "\n",
    "        print(\"\\n🔬 MODALITY-BASED PERFORMANCE\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        modality_df = pd.DataFrame(modality_metrics).T\n",
    "        modality_df = modality_df.round(4)\n",
    "        print(modality_df[['sample_count', 'rouge1_mean', 'rouge2_mean', 'rougeL_mean']])\n",
    "\n",
    "        # Overall performance\n",
    "        all_samples = []\n",
    "        for samples in modality_results.values():\n",
    "            all_samples.extend(samples)\n",
    "\n",
    "        overall_metrics = {\n",
    "            'total_samples': len(all_samples),\n",
    "            'overall_rouge1': np.mean([s['rouge1'] for s in all_samples]),\n",
    "            'overall_rouge2': np.mean([s['rouge2'] for s in all_samples]),\n",
    "            'overall_rougeL': np.mean([s['rougeL'] for s in all_samples])\n",
    "        }\n",
    "\n",
    "        print(f\"\\n📈 OVERALL PERFORMANCE\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Total samples evaluated: {overall_metrics['total_samples']}\")\n",
    "        print(f\"Average ROUGE-1: {overall_metrics['overall_rouge1']:.4f}\")\n",
    "        print(f\"Average ROUGE-2: {overall_metrics['overall_rouge2']:.4f}\")\n",
    "        print(f\"Average ROUGE-L: {overall_metrics['overall_rougeL']:.4f}\")\n",
    "\n",
    "        # Best and worst performing modalities\n",
    "        rouge1_by_modality = {mod: metrics['rouge1_mean'] for mod, metrics in modality_metrics.items()}\n",
    "        best_modality = max(rouge1_by_modality, key=rouge1_by_modality.get)\n",
    "        worst_modality = min(rouge1_by_modality, key=rouge1_by_modality.get)\n",
    "\n",
    "        print(f\"\\n🏆 Best performing modality: {best_modality} (ROUGE-1: {rouge1_by_modality[best_modality]:.4f})\")\n",
    "        print(f\"⚠️  Lowest performing modality: {worst_modality} (ROUGE-1: {rouge1_by_modality[worst_modality]:.4f})\")\n",
    "\n",
    "        return {\n",
    "            'modality_metrics': modality_metrics,\n",
    "            'overall_metrics': overall_metrics,\n",
    "            'detailed_results': modality_results\n",
    "        }\n",
    "\n",
    "    def save_results(self, results, filename=\"systematic_evaluation_results.json\"):\n",
    "        \"\"\"Save evaluation results to file\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"\\n💾 Results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2f21a2-8161-4866-8dba-4d581a0a5f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73d4740687843ff80faafb9e77d670f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Test dataset: 1915 samples\n",
      "Modalities: ['MR' 'CT' 'XR' 'CR' 'US' 'NM' 'nan' 'OTHER']\n",
      "Clinics: ['clinic_1' 'clinic_3' 'clinic_6' 'clinic_5' 'clinic_4' 'clinic_2' 'nan']\n",
      "\n",
      "📊 Dataset Distribution:\n",
      "          sample_count  clinic_count\n",
      "modality                            \n",
      "CR                 214             4\n",
      "CT                 243             6\n",
      "MR                1194             6\n",
      "NM                  16             3\n",
      "OTHER                2             2\n",
      "US                  38             4\n",
      "XR                 104             2\n",
      "nan                104             1\n",
      "\n",
      "🚀 Starting systematic evaluation...\n",
      "\n",
      "🔬 Evaluating modality: MR\n",
      "  Processing sample 1/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 4/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 5/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 6/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 7/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 8/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 9/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 10/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 11/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 12/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 13/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 14/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 15/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 16/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 17/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 18/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 19/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Evaluating modality: CT\n",
      "  Processing sample 1/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 4/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 5/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 6/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 7/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 8/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 9/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 10/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 11/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 12/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 13/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 14/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 15/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 16/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 17/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 18/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 19/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Evaluating modality: XR\n",
      "  Processing sample 1/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 4/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 5/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 6/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 7/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 8/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 9/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 10/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 11/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 12/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 13/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 14/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 15/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 16/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 17/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 18/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 19/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Evaluating modality: CR\n",
      "  Processing sample 1/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 4/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 5/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 6/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 7/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 8/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 9/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 10/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 11/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 12/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 13/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 14/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 15/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 16/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 17/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 18/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 19/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Evaluating modality: US\n",
      "  Processing sample 1/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 4/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 5/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 6/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 7/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 8/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 9/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 10/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 11/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 12/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 13/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 14/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 15/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 16/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 17/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 18/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 19/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Evaluating modality: NM\n",
      "  Processing sample 1/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 3/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 4/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 5/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 6/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 7/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 8/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 9/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 10/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 11/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 12/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 13/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 14/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 15/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 16/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Evaluating modality: nan\n",
      "  Processing sample 1/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 4/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 5/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 6/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 7/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 8/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 9/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 10/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 11/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 12/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 13/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 14/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 15/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 16/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 17/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 18/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 19/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Evaluating modality: OTHER\n",
      "  Processing sample 1/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing sample 2/2...\n",
      "\n",
      "================================================================================\n",
      "📊 SYSTEMATIC EVALUATION REPORT\n",
      "================================================================================\n",
      "\n",
      "🔬 MODALITY-BASED PERFORMANCE\n",
      "--------------------------------------------------\n",
      "       sample_count  rouge1_mean  rouge2_mean  rougeL_mean\n",
      "MR             20.0       0.4642       0.2927       0.3490\n",
      "CT             20.0       0.2836       0.1013       0.2101\n",
      "XR             20.0       0.2859       0.1521       0.2437\n",
      "CR             20.0       0.3283       0.1694       0.2754\n",
      "US             20.0       0.3073       0.1230       0.2542\n",
      "NM             16.0       0.3440       0.1825       0.2849\n",
      "nan            20.0       0.4186       0.2490       0.3082\n",
      "OTHER           2.0       0.2745       0.0833       0.1331\n",
      "\n",
      "📈 OVERALL PERFORMANCE\n",
      "------------------------------\n",
      "Total samples evaluated: 138\n",
      "Average ROUGE-1: 0.3465\n",
      "Average ROUGE-2: 0.1800\n",
      "Average ROUGE-L: 0.2727\n",
      "\n",
      "🏆 Best performing modality: MR (ROUGE-1: 0.4642)\n",
      "⚠️  Lowest performing modality: OTHER (ROUGE-1: 0.2745)\n",
      "\n",
      "💾 Results saved to systematic_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModalityBasedEvaluator()\n",
    "# Show dataset distribution\n",
    "print(\"\\n📊 Dataset Distribution:\")\n",
    "print(evaluator.get_modality_distribution())\n",
    "\n",
    "# Run systematic evaluation\n",
    "print(\"\\n🚀 Starting systematic evaluation...\")\n",
    "modality_results = evaluator.evaluate_by_modality(samples_per_modality=20)\n",
    "\n",
    "# Generate report\n",
    "final_results = evaluator.generate_evaluation_report(modality_results)\n",
    "\n",
    "# Save results\n",
    "evaluator.save_results(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e26053-c84f-42f3-8c55-30b75b933992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
